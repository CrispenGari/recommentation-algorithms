{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Recipe Recommentation Algorithims\n",
        "In this notebook we are going to create recommendation systems for the recipes. We are going to create the following recommendation algorithims based on what we have in our dataset.\n",
        "\n",
        "1. `Demographic Filtering`\n",
        "\n",
        "* In this algorithim we are going to generalise the recipes and recommend the recipes to all the users. We are going to use this recommendation to recommend good recipes to the user when the user does not have either:\n",
        "  * search history\n",
        "  * recently liked recipes\n",
        "* As soon as the user have that we are going to switch from using this algorithm to something that suits the user.\n",
        "\n",
        "> Demographic filtering is a simple algorithm that recommends users products based on the context that, recipes that are popular and critically acclaimed will have a higher probability of being liked by the average audience.\n",
        "\n",
        "\n",
        "\n",
        "2. `Content Based Filtering`\n",
        "* We are going to futher on create an algorithm that will recomment the user recipes if he/she has:\n",
        "  * search history about recipes\n",
        "  * recently liked recipes\n",
        "* In this system we are going to use recipe metadata, such as `category`, `author`, `description` and `difficult`, etc., to make these recommendations.\n",
        "\n",
        "> The general idea behind these recommender systems is that if a person liked a particular item, he or she will also like an item that is similar to it.\n",
        "\n",
        "* for `Content Based Filtering` we are going to create `2` algorithms the other one will be used to search and the other one will be used to recomend.\n",
        "\n",
        "### Data\n",
        "\n",
        "The data that we are going to use in this notebook was scraped from [bccgoodfood.com](https://www.bbcgoodfood.com/) and the process of scrapping data and cleaning the data can be found in [these notebooks](https://github.com/CrispenGari/web-scrapping-python/tree/main/bs4/00_RECIPES). The data files that we will be using can also be found on [my gists](https://gist.github.com/CrispenGari/794a10de80b0bc3f5ff3a7b99ebb88de). The following are the files that we are going to have:\n",
        "\n",
        "```shell\n",
        "- recipes.json\n",
        "- health.json\n",
        "- baking.json\n",
        "- budget.json\n",
        "- inspiration.json\n",
        "- flattened_recipes.json\n",
        "```\n",
        "### Data Preparation\n",
        "\n",
        "The data that we are going to have here is in `json` format.\n",
        "\n",
        "\n",
        "### Imports\n",
        "In the following code cell we are going to import all the packages that we are going to use in this notebook.\n"
      ],
      "metadata": {
        "id": "6kzl8tT1pi-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import os\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from ast import literal_eval\n",
        "\n",
        "from google.colab import drive, files"
      ],
      "metadata": {
        "id": "rBqjvwJCpjv9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Demographic Recommendation\n",
        "\n",
        "Our system will demographically recommend recipes based on the category among the following categories:\n",
        "\n",
        "```shell\n",
        "- recipes\n",
        "- health\n",
        "- baking\n",
        "- budget\n",
        "- inspiration\n",
        "```\n",
        "\n",
        "So we need to create `5` different demographic models that will recommend the recipe based on it's category. Befor anything:\n",
        "\n",
        "\n",
        "1. We need a metric to `score` or rate recipe\n",
        "2. Calculate the `score` for every recipe\n",
        "3. `Sort` the scores and recommend the best rated recipe to the users.\n",
        "\n",
        "> We can use the average ratings of a recipe as the score but using this won't be fair enough since a recipe with `4.3` average rating and only `3` votes cannot be considered better than the recipe with `3.8` as as average rating but 40 votes. So, we'll be using `IMDB's weighted rating (wr)` which is given as :-\n",
        "\n",
        "<p align=\"center\"><img src=\"https://camo.githubusercontent.com/3210726e3fc7a95bd6b46a0a4557997c8f32350911442a32c8e929c8e131cd46/68747470733a2f2f696d6167652e6962622e636f2f6a59575a70392f77722e706e67\" alt=\"img\" /></p>\n",
        "\n",
        "\n",
        "where:\n",
        "\n",
        "* $v$ - is the number of votes for the recipe;\n",
        "* $m$ - is the minimum votes required to be listed in the chart;\n",
        "  *  $m$, the minimum votes required to be listed in the chart. We will use `90th` percentile as our cutoff. In other words, for a movie to feature in the charts, it must have more votes than at least `90%` of the movies in the list.\n",
        "* $R$ - is the average rating of the recipe; And\n",
        "* $C$ - is the mean vote across the whole report\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8VHblQ7p4Zlx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DR:\n",
        "  def __init__(self, filename: str):\n",
        "    self.filename= filename\n",
        "    self.dataframe = pd.read_json(filename)\n",
        "    self.C = self.dataframe.rattings.mean()\n",
        "    self.m = self.dataframe.vote_count.quantile(0.9)\n",
        "  def weighted_rating(self, dataframe):\n",
        "      v = dataframe.vote_count\n",
        "      R = dataframe.rattings\n",
        "      return (v/(v+self.m) * R) + (self.m/(self.m+v) * self.C)\n",
        "\n",
        "  def __call__(self):\n",
        "    self.dataframe['score'] = self.dataframe.apply(self.weighted_rating, axis=1)\n",
        "    self.dataframe.sort_values('score', ascending=False, inplace=True)\n",
        "    return [i for i in self.dataframe['id'].head()]\n",
        "\n",
        "DR('recipes.json')()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ed1iHw5c5-v4",
        "outputId": "9fa01a74-3f0d-48f5-fe52-924bf9eaf979"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['c5aa4a2e-79bc-4c9c-af9b-52e244ec1220',\n",
              " 'f174da06-5cec-4338-b268-317876fface8',\n",
              " 'c771aeac-b2df-46f0-8abb-093a71bee95c',\n",
              " 'c83a5362-cba4-4f59-a398-1058bdcf6300',\n",
              " '0cae51e1-3159-484f-9403-37fa80dea3b7']"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Content Based Filtering and Recommendation\n",
        "\n",
        "Now that we created a simple demographic recommandation algorithing for all the users that does not have `search-history` and `recipes-liked`. We want to create other algorithims that will be able to recommend or recipes based on the `search-history` and `recipes-liked` using `decription` and other meta data.\n",
        "\n",
        "So we are going to use `2` algorithm, the one that uses decription to recomment recipes and the other one that will use metadata to recomment recipes. These functions will return a list of `recipes` id that the system is recommending.\n"
      ],
      "metadata": {
        "id": "jDEvSV5RB1D8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_recommendations_from_description(name, filename):\n",
        "  \"\"\"\n",
        "  The idea is that when you like or search the recipe of this name,\n",
        "  you probabbly want the simmilar recipes to that one.\n",
        "  \"\"\"\n",
        "  dataframe = pd.read_json(filename)\n",
        "  tfidf = TfidfVectorizer(stop_words='english')\n",
        "  tfidf_matrix = tfidf.fit_transform(dataframe.description)\n",
        "  cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "  indices = pd.Series(dataframe.index, index=dataframe['name']).drop_duplicates()\n",
        "  idx = indices[name]\n",
        "  sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "  sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "  sim_scores = sim_scores[:11]\n",
        "  recipe_indices = [i[0] for i in sim_scores]\n",
        "  return [i for i in dataframe['id'].iloc[recipe_indices]]\n",
        "get_recommendations_from_description(\"Smoked salmon, quinoa & dill lunch pot\", \"recipes.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCnaxvE-DXCF",
        "outputId": "22b7025d-59c3-4d59-c2a7-d49bba77f8d2"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['7bac6ec3-fb66-4543-80f5-4b692de7a811',\n",
              " '2eb91edf-06c5-4df6-bd8d-2f46cede0e02',\n",
              " '7b2562da-aabd-4fcd-9924-a924bcee1560',\n",
              " 'bcd9ff50-69a5-4289-9aa5-f3a8f1bc9fd0',\n",
              " '6896cade-c070-4ef1-9863-149c4599c78a',\n",
              " 'eafda57d-db94-4ed5-8a5c-fee0688b61e1',\n",
              " '3dca0ef0-5503-450f-bc4e-681b332adf7c',\n",
              " '25fb0357-f11d-49f1-8f43-27cedcabda69',\n",
              " '83773965-f6a2-44f9-a579-a812e1349caa',\n",
              " '4043cb11-be1c-47fd-9aa9-1df2ef322e21',\n",
              " '3e4f3819-86bf-4d55-984b-1b52957db766']"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = ['author', 'difficult', 'subcategory', 'dish_type', 'maincategory']\n",
        "def clean_data(x):\n",
        "  if isinstance(x, str):\n",
        "    return str.lower(x.replace(\" \", \"\"))\n",
        "  else:\n",
        "    return ''\n",
        "\n",
        "def create_soup(x):\n",
        "  return x['author'] + x['difficult'] + ' ' + x['subcategory']  + ' ' + x['dish_type']+ ' ' + x['maincategory']\n",
        "\n",
        "def get_recommendations_from_meta_data(name, filename):\n",
        "  dataframe = pd.read_json(filename)\n",
        "  for feature in features:\n",
        "    dataframe[feature] = dataframe[feature].apply(clean_data)\n",
        "  dataframe['soup'] = dataframe.apply(create_soup, axis=1)\n",
        "  count = CountVectorizer(stop_words='english')\n",
        "  count_matrix = count.fit_transform(dataframe.soup)\n",
        "  cosine_sim = cosine_similarity(count_matrix, count_matrix)\n",
        "  indices = pd.Series(dataframe.index, index=dataframe.name)\n",
        "  idx = indices[name]\n",
        "  sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "  sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "  sim_scores = sim_scores[0:11]\n",
        "  recipes_indices = [i[0] for i in sim_scores]\n",
        "  return [i for i in dataframe['id'].iloc[recipes_indices]]\n",
        "get_recommendations_from_meta_data(\"Smoked salmon, quinoa & dill lunch pot\", \"recipes.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZIpdphfEnmK",
        "outputId": "6b7c8e90-55b5-46a9-df3b-35e59cce30fd"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['7bac6ec3-fb66-4543-80f5-4b692de7a811',\n",
              " 'e2707dfa-22de-4290-9239-c2a4c64e285d',\n",
              " '945da5ed-e263-4d28-a791-8e94c3c5f57c',\n",
              " '25009e0a-0e60-4169-9f76-f464225549a9',\n",
              " '63ff8ff6-2871-4e92-96fd-39964c423a39',\n",
              " '9e62330f-5ea0-4c2a-b0c8-edf386b63fb7',\n",
              " 'c095701c-a11e-4f47-90a0-a3ea20f7c752',\n",
              " 'dfe9a8ed-576e-4d01-b2f9-b622d09da03b',\n",
              " '25ad8549-7f6c-47cc-9c4b-79df9d80e3a9',\n",
              " '7d28c52d-7c2b-450b-9e70-3f7e9319ff1e',\n",
              " '97ba01d2-9fbc-4b43-93da-5061256c99c4']"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Refs\n",
        "\n",
        "1. [00_MOVIE_RECOMMENTATION_SYSTEM.ipynb](https://github.com/CrispenGari/recommentation-algorithms/blob/main/00_MOVIE_RECOMMENTATION_SYSTEM/00_MOVIE_RECOMMENTATION_SYSTEM.ipynb)"
      ],
      "metadata": {
        "id": "rGu3Tm6QL-_a"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "llXcq_sZMEiR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}